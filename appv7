import streamlit as st
import pandas as pd
import time
import random
import os
import requests

# -----------------------------
# Auth / Config (unchanged)
# -----------------------------
if "user_access_token" not in st.session_state:
    st.session_state.user_access_token = os.environ.get("DATABRICKS_TOKEN")

host_name = "https://adb-640321604414221.1.azuredatabricks.net"
space_id = '01f0a7f4557013988ce0f20db008067e'
Conversation_url = f"{host_name}/api/2.0/genie/spaces/{space_id}/start-conversation"


def New_Chat(user_input):
    response = requests.post(
        Conversation_url,
        headers={
            "Authorization": f"Bearer {st.session_state.user_access_token}",
            "Content-Type": "application/json"
        },
        json={"content": user_input}
    )
    conversation_id = response.json().get("conversation_id")
    message_id = response.json().get("message_id")
    return conversation_id, message_id


def fetch_question_response(conversation_id, message_id):
    response_url = f"{host_name}/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}"
    query_response = requests.get(
        response_url,
        headers={
            "Authorization": f"Bearer {st.session_state.user_access_token}",
            "Content-Type": "application/json"
        }
    )
    return query_response


def fetch_results(conversation_id, message_id, attachment_id):
    execute_url = f"{host_name}/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/attachments/{attachment_id}/execute-query"
    results = requests.post(
        execute_url,
        headers={
            "Authorization": f"Bearer {st.session_state.user_access_token}",
            "Content-Type": "application/json"
        }
    )
    return results


def get_data(conversation_id, message_id, attachment_id):
    get_data_url = f"{host_name}/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/attachments/{attachment_id}/query-result"
    results = requests.get(
        get_data_url,
        headers={
            "Authorization": f"Bearer {st.session_state.user_access_token}",
            "Content-Type": "application/json"
        }
    )
    return results


def context_chat(user_input, conversation_id):
    message_url = f"{host_name}/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages"
    response = requests.post(
        message_url, headers={
            "Authorization": f"Bearer {st.session_state.user_access_token}",
            "Content-Type": "application/json"
        },
        json={"content": user_input}
    )
    message_id = response.json().get("message_id")
    return response.json(), message_id


def feedback(conversation_id, message_id, feedback_res):
    st.write("feedback_res is ", feedback_res)
    feedback_url = f"{host_name}/api/2.0/genie/spaces/{space_id}/conversations/{conversation_id}/messages/{message_id}/feedback"
    response = requests.post(
        feedback_url, headers={
            "Authorization": f"Bearer {st.session_state.user_access_token}",
            "Content-Type": "application/json"
        },
        json={"rating": feedback_res}
    )
    return response.json()


# -----------------------------
# Page setup
# -----------------------------
st.set_page_config(page_title="💬 Smart Data Assistant", layout="wide")

# -----------------------------
# Theming & CSS (UI ONLY)
# -----------------------------
st.markdown("""
<style>
/* Global reset / typography */
:root {
  --bg: #0b0f14;               /* dark canvas (like ChatGPT) */
  --panel: #11161c;            /* chat panel background */
  --panel-2: #0f141a;          /* header/composer background */
  --text: #e8eef6;             /* primary text */
  --text-dim: #b7c1d0;         /* secondary text */
  --accent: #10a37f;           /* brand green */
  --bubble-user: #1a2330;      /* user bubble */
  --bubble-ai: #161d26;        /* ai bubble */
  --code-bg: #0f1720;          /* code/sql bg */
  --border: #1f2a37;           /* subtle border */
  --shadow: rgba(0,0,0,0.35);
}

html, body, [data-testid="stAppViewContainer"] {
  background: var(--bg);
  color: var(--text);
}

/* Hide default Streamlit chrome for cleaner look */
[data-testid="stToolbar"] { display: none !important; }
#MainMenu { visibility: hidden; }
footer { visibility: hidden; }

/* Header bar */
.header {
  position: sticky;
  top: 0;
  z-index: 50;
  backdrop-filter: blur(6px);
  background: linear-gradient( to bottom, rgba(15,20,26,0.95), rgba(15,20,26,0.80) );
  border-bottom: 1px solid var(--border);
  padding: 14px 16px;
  display: flex;
  align-items: center;
  gap: 12px;
}
.header .title {
  font-weight: 700;
  font-size: 18px;
  letter-spacing: 0.3px;
}
.header .chip {
  margin-left: auto;
  background: #0d1a14;
  color: #97f3d9;
  border: 1px solid #1b3a2d;
  padding: 4px 10px;
  border-radius: 999px;
  font-size: 12px;
}

/* Main chat surface */
.chat-surface {
  background: var(--panel);
  border: 1px solid var(--border);
  border-radius: 16px;
  padding: 12px 0;
  margin-top: 12px;
  box-shadow: 0 6px 24px var(--shadow);
  min-height: 68vh;
}

/* Each exchange (question+answer) aligns like ChatGPT */
.turn {
  padding: 8px 24px;
}

/* User message row */
.row {
  display: grid;
  grid-template-columns: 52px 1fr;
  gap: 14px;
  align-items: flex-start;
  margin: 8px 0 6px 0;
}

/* Avatar */
.avatar {
  width: 40px; height: 40px;
  border-radius: 8px;
  display: grid; place-items: center;
  border: 1px solid var(--border);
  color: var(--text-dim);
  background: var(--panel-2);
  font-size: 20px;
}

/* Bubbles */
.bubble {
  border: 1px solid var(--border);
  border-radius: 14px;
  padding: 12px 14px;
  line-height: 1.55;
  box-shadow: 0 2px 12px rgba(0,0,0,0.12);
  color: var(--text);
}
.user { background: var(--bubble-user); }
.assistant { background: var(--bubble-ai); }

/* Question styling (keep your semantics but prettier) */
.question-text {
  font-weight: 500;
  color: #e5edf7;
}
.answer-text {
  color: var(--text);
}

/* SQL toggle + code block */
.sql-toggle {
  margin-top: 8px;
}
.sql-box {
  background-color: var(--code-bg);
  color: #d7e2f0;
  padding: 12px;
  border-radius: 12px;
  font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  border: 1px solid var(--border);
  font-size: 13px;
  white-space: pre-wrap;
}

/* Feedback buttons row */
.feedback-row {
  display: flex;
  gap: 8px;
  align-items: center;
  margin-top: 10px;
}
.feedback-btn {
  background-color: #14202b;
  border-radius: 10px;
  padding: 6px 10px;
  border: 1px solid var(--border);
  cursor: pointer;
  transition: transform 0.06s ease, background 0.2s ease;
  color: var(--text-dim);
  font-size: 14px;
}
.feedback-btn:hover {
  background: #0f1a24;
  transform: translateY(-1px);
}

/* Dataframe wrapper */
.df-wrap {
  margin-top: 8px;
  border: 1px solid var(--border);
  border-radius: 12px;
  overflow: hidden;
}

/* Sticky composer at bottom like ChatGPT */
.composer {
  position: sticky;
  bottom: 0;
  z-index: 60;
  padding: 14px 0 6px 0;
  background: linear-gradient( to top, rgba(17,22,28,0.98), rgba(17,22,28,0.90) );
  border-top: 1px solid var(--border);
  backdrop-filter: blur(6px);
}
.composer-inner {
  display: grid;
  grid-template-columns: 1fr 110px;
  gap: 10px;
  align-items: center;
}
.composer .send-btn {
  background: var(--accent);
  color: #041410;
  font-weight: 700;
  border: 0;
  border-radius: 10px;
  padding: 14px 14px;
  cursor: pointer;
  box-shadow: 0 4px 14px rgba(16,163,127,0.35);
}
.composer .send-btn:hover {
  filter: brightness(1.05);
}

/* Make Streamlit inputs match dark theme */
[data-testid="stTextInput"] input {
  background: #0f141a;
  color: var(--text);
  border: 1px solid var(--border);
  border-radius: 10px;
  padding: 14px 12px;
}
[data-testid="stTextInput"] label {
  color: var(--text-dim) !important;
}

/* Surface spacing tweak to leave room for sticky composer */
.bottom-spacer { height: 84px; }

/* Subtle status spinner text */
.status {
  font-size: 12px;
  color: var(--text-dim);
  margin-top: 4px;
}
</style>
""", unsafe_allow_html=True)

# -----------------------------
# Session state (unchanged keys)
# -----------------------------
if "conversation_id" not in st.session_state:
    st.session_state.conversation_id = None
if "show_sql" not in st.session_state:
    st.session_state.show_sql = {}
if "message_id" not in st.session_state:
    st.session_state.message_id = None
if "qa_history" not in st.session_state:
    st.session_state.qa_history = []

# -----------------------------
# Dummy backend text generator (unchanged behavior)
# -----------------------------
def generate_answer(question):
    simulated_responses = [
        "Sure! Let’s pull up the data for that.",
        "Fetching the information you requested…",
        "Here’s what I found in the dataset."
    ]
    answer_text = random.choice(simulated_responses)
    return answer_text

# -----------------------------
# Header Bar
# -----------------------------
st.markdown(
    """
    <div class="header">
      <div class="title">💬 Smart Data Assistant</div>
      <div class="chip">Connected · Databricks Genie</div>
    </div>
    """,
    unsafe_allow_html=True
)

# -----------------------------
# Chat Surface Container
# -----------------------------
with st.container():
    st.markdown('<div class="chat-surface">', unsafe_allow_html=True)

    # --- Input section (moved to sticky composer but logic is identical) ---
    # Keeping your variable names and submission flow exactly the same.
    with st.container():
        # We render the composer now but we still use your existing submit+user_input variables.
        c1, c2, c3 = st.columns([1, 6, 1])
        with c2:
            st.markdown('<div class="composer">', unsafe_allow_html=True)
            st.markdown('<div class="composer-inner">', unsafe_allow_html=True)

            # Keep same widget types/names so behavior is unchanged
            user_input = st.text_input("Ask me anything:", placeholder="Send a message...", label_visibility="collapsed", key="composer_input")
            submit = st.button("Send", type="primary", use_container_width=True)

            st.markdown('</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

    # --- Submission & core logic (UNCHANGED) ---
    if submit and user_input.strip():
        with st.spinner("Thinking..."):
            # Insert empty response at top (preserve your order)
            st.session_state.qa_history.insert(0, {
                "question": user_input,
                "answer_text": "",
                "answer_df": None,
                "sql": "",
                "feedback": None
            })

            if st.session_state.conversation_id is None:
                st.session_state.conversation_id, st.session_state.message_id = New_Chat(user_input)
                conversation_id = st.session_state.conversation_id
                message_id = st.session_state.message_id
            else:
                response, st.session_state.message_id = context_chat(user_input, st.session_state.conversation_id)
                message_id = st.session_state.message_id
                st.write("Existing Conversation")

            query_response = fetch_question_response(st.session_state.conversation_id, message_id)
            while True:
                query_response = fetch_question_response(st.session_state.conversation_id, message_id)
                data = query_response.json()
                time.sleep(5)
                with st.spinner(data.get("status")):
                    if data.get("status") in ("COMPLETED", "FAILED"):
                        break

            SQL = data.get("attachments")[0]["query"]["query"]
            attachment_id = data.get("attachments")[0]["attachment_id"]
            result_response = fetch_results(st.session_state.conversation_id, message_id, attachment_id)
            result_fetch = get_data(st.session_state.conversation_id, message_id, attachment_id)

            while True:
                query_response = get_data(st.session_state.conversation_id, message_id, attachment_id)
                data = query_response.json()
                state = data["statement_response"]["status"]["state"]
                if state in ("SUCCEEDED", "FAILED "):
                    break

            columns = data["statement_response"]["manifest"]["schema"]["columns"]
            col_names = [col["name"] for col in columns]
            rows = data["statement_response"]["result"]["data_array"]
            Answer = pd.DataFrame(rows, columns=col_names)

            # Simulate streaming effect (unchanged)
            answer_text = generate_answer(user_input)
            partial_text = ""
            for ch in answer_text:
                partial_text += ch
                st.session_state.qa_history[0]["answer_text"] = partial_text
                time.sleep(0.03)

            # Attach df and SQL
            st.session_state.qa_history[0]["answer_df"] = Answer
            st.session_state.qa_history[0]["sql"] = SQL

            if len(st.session_state.qa_history) > 50:
                st.session_state.qa_history = st.session_state.qa_history[:50]

    # --- Display chat history (UI ONLY CHANGED; logic intact) ---
    # Render oldest -> newest so the latest appears at the bottom like ChatGPT,
    # without changing how you store items (you still insert at index 0).
    history_for_display = list(reversed(st.session_state.qa_history))

    for i_display, qa in enumerate(history_for_display):
        # Map back to the original index for toggles/feedback keys
        # original_idx: compute position in original list
        original_idx = len(st.session_state.qa_history) - 1 - i_display

        # USER ROW
        st.markdown('<div class="turn">', unsafe_allow_html=True)
        st.markdown('<div class="row">', unsafe_allow_html=True)
        st.markdown('<div class="avatar">🧑‍💻</div>', unsafe_allow_html=True)
        st.markdown(
            f'<div class="bubble user"><div class="question-text">{qa["question"]}</div></div>',
            unsafe_allow_html=True
        )
        st.markdown('</div>', unsafe_allow_html=True)

        # ASSISTANT ROW
        st.markdown('<div class="row">', unsafe_allow_html=True)
        st.markdown('<div class="avatar">🤖</div>', unsafe_allow_html=True)
        st.markdown(
            f'<div class="bubble assistant"><div class="answer-text">{qa["answer_text"]}</div>',
            unsafe_allow_html=True
        )

        # Dataframe
        if qa["answer_df"] is not None:
            st.markdown('</div>', unsafe_allow_html=True)  # close bubble open before dataframe
            st.markdown('<div class="row"><div></div><div class="bubble assistant">', unsafe_allow_html=True)
            st.markdown('<div class="df-wrap">', unsafe_allow_html=True)
            st.dataframe(qa["answer_df"], use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)

            # SQL toggle
            if st.button(
                "Show SQL" if not st.session_state.show_sql.get(original_idx) else "Hide SQL",
                key=f"sqlbtn_{original_idx}",
                use_container_width=True
            ):
                st.session_state.show_sql[original_idx] = not st.session_state.show_sql.get(original_idx, False)

            if st.session_state.show_sql.get(original_idx):
                st.markdown(f"<div class='sql-box'>{qa['sql']}</div>", unsafe_allow_html=True)

            # Feedback row
            st.markdown('<div class="feedback-row">', unsafe_allow_html=True)
            col1, col2, col3, col4 = st.columns([1, 1, 1, 6])
            with col1:
                if st.button("👍", key=f"good_{original_idx}"):
                    qa["feedback"] = "POSITIVE"
                    feedback(st.session_state.conversation_id, st.session_state.message_id, "POSITIVE")
            with col2:
                if st.button("😐", key=f"neutral_{original_idx}"):
                    qa["feedback"] = "Neutral"
                    feedback(st.session_state.conversation_id, st.session_state.message_id, "NONE")
            with col3:
                if st.button("👎", key=f"bad_{original_idx}"):
                    qa["feedback"] = "NEGATIVE"
                    feedback(st.session_state.conversation_id, st.session_state.message_id, "NEGATIVE")
            with col4:
                if qa.get("feedback"):
                    st.markdown(f"**Feedback:** {qa['feedback']}")

            st.markdown('</div>', unsafe_allow_html=True)  # close feedback-row
            st.markdown('</div>', unsafe_allow_html=True)  # close bubble assistant wrapper
        else:
            # close assistant bubble if no dataframe block intervened
            st.markdown('</div>', unsafe_allow_html=True)

        st.markdown('</div>', unsafe_allow_html=True)  # close row
        st.markdown('</div>', unsafe_allow_html=True)  # close turn

    # spacer so last messages aren't hidden behind sticky composer
    st.markdown('<div class="bottom-spacer"></div>', unsafe_allow_html=True)

    st.markdown('</div>', unsafe_allow_html=True)  # close chat-surface
